<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="If we don&rsquo;t need to train our own model from scratch, we can use In Contextual Learning approach. In contextual learning"><meta property="og:title" content="LLM app architecture"><meta property="og:description" content="If we don&rsquo;t need to train our own model from scratch, we can use In Contextual Learning approach. In contextual learning"><meta property="og:type" content="website"><meta property="og:image" content="https://secondbrain.chiragsehra.dev/icon.png"><meta property="og:url" content="https://secondbrain.chiragsehra.dev/notes/Emerging-Architectures-for-LLM-apps/"><meta property="og:width" content="200"><meta property="og:height" content="200"><meta name=twitter:card content="summary"><meta name=twitter:title content="LLM app architecture"><meta name=twitter:description content="If we don&rsquo;t need to train our own model from scratch, we can use In Contextual Learning approach. In contextual learning"><meta name=twitter:image content="https://secondbrain.chiragsehra.dev/icon.png"><meta name=twitter:site content="HashChirag"><title>LLM app architecture</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://secondbrain.chiragsehra.dev//icon.png><link href=https://secondbrain.chiragsehra.dev/styles.19109a40042e9f0e72e952fda4442a34.min.css rel=stylesheet><link href=https://secondbrain.chiragsehra.dev/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://secondbrain.chiragsehra.dev/js/darkmode.3940b1339c02f0b5a44481e778c4fb21.min.js></script>
<script src=https://secondbrain.chiragsehra.dev/js/util.00639692264b21bc3ee219733d38a8be.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/core@1.2.1></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/dom@1.2.1></script>
<script defer src=https://secondbrain.chiragsehra.dev/js/popover.aa9bc99c7c38d3ae9538f218f1416adb.min.js></script>
<script defer src=https://secondbrain.chiragsehra.dev/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://secondbrain.chiragsehra.dev/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://secondbrain.chiragsehra.dev/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://secondbrain.chiragsehra.dev/",fetchData=Promise.all([fetch("https://secondbrain.chiragsehra.dev/indices/linkIndex.5280f7bc16450265ab841537aab25e0d.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://secondbrain.chiragsehra.dev/indices/contentIndex.526f8afb0e6e8fb75bf6feee65c03793.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://secondbrain.chiragsehra.dev",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://secondbrain.chiragsehra.dev",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()});function a(n){const e=n.target,t=e.className.split(" "),s=t.includes("broken"),o=t.includes("internal-link");plausible("Link Click",{props:{href:e.href,broken:s,internal:o,graph:!1}})}const r=document.querySelectorAll("a");for(link of r)link.className.includes("root-title")&&link.addEventListener("click",a,{once:!0})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'â€™':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/secondbrain.chiragsehra.dev\/js\/router.d6fe6bd821db9ea97f9aeefae814d8e7.min.js"
    attachSPARouting(init, render)
  </script><script defer data-domain=secondbrain.chiragsehra.dev src=https://plausible.io/js/script.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://secondbrain.chiragsehra.dev/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div class=singlePage><header><h1 id=page-title><a class=root-title href=https://secondbrain.chiragsehra.dev/>ðŸ§  Sehra's Second Brain</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>LLM app architecture</h1><p class=meta>Last updated
Jul 8, 2023
<a href=https://github.com/chiragsehra/quartz/tree/hugo/content/notes/Emerging%20Architectures%20for%20LLM%20apps.md rel=noopener>Edit Source</a></p><ul class=tags><li><a href=https://secondbrain.chiragsehra.dev/tags/llms/>Llms</a></li><li><a href=https://secondbrain.chiragsehra.dev/tags/dataprocessing/>Dataprocessing</a></li><li><a href=https://secondbrain.chiragsehra.dev/tags/prompting/>Prompting</a></li><li><a href=https://secondbrain.chiragsehra.dev/tags/tools/>Tools</a></li><li><a href=https://secondbrain.chiragsehra.dev/tags/langchain/>Langchain</a></li></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#stages>Stages</a><ol><li><a href=#data-preprocessing-and-creating-embeddings>Data preprocessing and creating embeddings</a></li><li><a href=#what-is-contextual-data>What is contextual data?</a></li><li><a href=#what-are-embeddings>What are embeddings?</a></li><li><a href=#what-are-vector-databases>What are vector databases?</a></li></ol></li><li><a href=#prompt-construction-and-retrieval>Prompt Construction and Retrieval</a></li><li><a href=#prompt-creation-and-retrieval-for-sme>Prompt Creation and Retrieval for SME</a></li><li><a href=#prompt-executioninference>Prompt Execution/Inference</a></li></ol></nav></details></aside><p>If we don&rsquo;t need to train our own model from scratch, we can use <strong><code>In Contextual Learning</code></strong>
approach.
In contextual learning</p><ul><li>is clever prompting</li><li>sharing only relevant documents with LLM, instead of sharing the complete bunch of information</li></ul><a href=#stages><h2 id=stages><span class=hanchor arialabel=Anchor># </span>Stages</h2></a><ul><li>Data Preprocessing and Creating embedding</li><li>Prompt Construction and retrieval</li><li>Prompt Execution and Inference</li></ul><a href=#data-preprocessing-and-creating-embeddings><h3 id=data-preprocessing-and-creating-embeddings><span class=hanchor arialabel=Anchor># </span>Data preprocessing and creating embeddings</h3></a><ul><li>Storing private data to be used later.</li><li>Break the documents into chunks, pass through embedding model and then storing in a vector database.</li></ul><p><img src="/notes/images/data_preprocessing and embedding creation.png" width=auto></p><a href=#what-is-contextual-data><h3 id=what-is-contextual-data><span class=hanchor arialabel=Anchor># </span>What is contextual data?</h3></a><p>Contextual data is the text documents, PDFs, or any structured format information like CSVs and SQL tables.</p><p>In the data ingestion process, we can use dataops etl tools to build wrappers for ingesting and all these structured format information to feed to our embedding model</p><a href=#what-are-embeddings><h3 id=what-are-embeddings><span class=hanchor arialabel=Anchor># </span>What are embeddings?</h3></a><ul><li>Embedding are vectors that represent the meaning of a sentence<ul><li>OpenAI API</li><li>Cohere</li><li>Opensource models from Huggingface</li></ul></li></ul><a href=#what-are-vector-databases><h3 id=what-are-vector-databases><span class=hanchor arialabel=Anchor># </span>What are vector databases?</h3></a><ul><li>store efficiently embeddings and query them quickly.</li><li>Vector databases that can be used:<ul><li>Opensource system - Weaviate, Vespa and Qdrant</li><li>Local Vector Management Library: Chroma and FAISS</li><li><code>pgvector</code> for postgres</li></ul></li></ul><a href=#prompt-construction-and-retrieval><h2 id=prompt-construction-and-retrieval><span class=hanchor arialabel=Anchor># </span>Prompt Construction and Retrieval</h2></a><p><img src=/notes/images/prompt_construction_end_user.png width=auto></p><ol><li>End user queries the hosted app with the question.</li><li>Question is sent to the <code>Langchain Master Orchestrator</code> #langchain</li><li>#langchain sends a request to embedding store to chunk the question</li><li>The chunks are queries on a #vectordb .</li><li>#vectordb returns the response to #langchain</li><li>#langchain orchestration can return the response on the hosted app or toggle some APIs/Plugins to perform some action based on the response returned. (example: the returned response contains a suggestion to reset the connection and open a new connection. The APIs/Plugins can help to open a ticket in JIRA for the operation team to visit the customer and reset their connection or send a signal to reset the connection.)</li><li>Once an action is toggled by the APIs/Plugins, the hosted app can show the notification to approve by the end user to either <code>approve</code> or <code>decline</code> the action suggested.</li></ol><a href=#prompt-creation-and-retrieval-for-sme><h2 id=prompt-creation-and-retrieval-for-sme><span class=hanchor arialabel=Anchor># </span>Prompt Creation and Retrieval for SME</h2></a><p><img src=/notes/images/prompt_creation_sme.png width=auto></p><ol><li>SME interacts in a <code>testing</code> setup i.e. in the <code>Prompt Lab</code>. This lab offers the capability to test prompts against various version of the LLM model and change hyper-parameters like <code>temperature</code> etc.</li><li>The request is forwarded to <code>Langchain Master Orchestration</code>. #langchain</li><li>The request received by #langchain is converted into chunks by the embedding store.</li><li>These chunks are queried on the #vectordb</li><li>#vectordb returns the response to #langchain orchestration.</li><li>#langchain orchestration can return the response on the <code>Prompt Lab</code> or toggle some APIs/Plugins to perform some action based on the response returned. (example: the returned response contains a suggestion to reset the connection and open a new connection. The APIs/Plugins can help to open a ticket in JIRA for the operation team to visit the customer and reset their connection or send a signal to reset the connection.)</li><li>Once an action is toggled by the APIs/Plugins, the hosted app can show the notification to approve by the end user to either <code>approve</code> or <code>decline</code> the action suggested.</li></ol><p>Another thing to add here is that SME would be able to provide feedback to the responses and help in structuring the next knowledge base for LLM to be trained on and the Prompt Optimisation.</p><a href=#prompt-executioninference><h2 id=prompt-executioninference><span class=hanchor arialabel=Anchor># </span>Prompt Execution/Inference</h2></a><p><img src=/notes/images/prompt_execution_inference.png width=auto></p><ol><li><strong>LLM Cache</strong>:<ol><li>Caching the frequently accessed content which is popular and trending.</li><li>Helps in reducing retrieval time, improves response time and eases burdens on the backend servers.</li><li>Read more about <code>Semantic Caching</code> - stores similar or related queries, thereby increasing cache hit probability and overall caching efficiency.</li><li>What can be used?<ol><li>Redis</li><li>SQLite</li><li>GPTCache</li></ol></li></ol></li><li><strong>Logging/MLOPS/LLMOPS</strong><ol><li>Logging of replies from LLMs</li><li>Managing and versioning dynamic prompts</li><li>Scoring of different versions of LLM with rapid development</li><li>What can be used?<ol><li>Weights and Biases</li><li>MLflow</li><li>PromptLayer</li><li>Helicone</li></ol></li></ol></li><li>Verification and Validation<ol><li>Avoiding to share PII data with LLMs</li><li>Manging Privacy and Anonimity</li><li>What can be used?<ol><li>Guardrails</li><li>Redbuff</li><li>Guidance</li><li>LMQL</li></ol></li></ol></li><li>LLMs API and Hosting<ol><li>Telco LLM API:<ol><li>Modular APIs to be shared with different clients to use our LLM and pay per API call based on tokens (similar pricing model as OpenAI)</li><li>What can be used?<ol><li>OpenAI</li><li>Anthropic</li></ol></li></ol></li><li>Opensource LLM API:<ol><li>Build a Leaderboard for all Telco Opensource LLMs trained. These LLMs help to achieve <code>Prompt Optimization</code> using <em>Chain of thought</em> or <code>Knowledge Retrieval Systems</code> prompting</li><li>What can be used?<ol><li>Hugging Face</li><li>Replicate</li></ol></li></ol></li><li>Hyperscaler Hosting<ol><li>Model fine tuning and hyper-parameter tests on GPUs on cloud</li><li>What can be used?<ol><li>AWS</li><li>GCP</li><li>Azure</li><li>Corewave</li><li>OVH</li></ol></li></ol></li><li>Notebooks on Cloud<ol><li>Experiments and Jupyter notebooks</li><li>What can be used?<ol><li>Jupyterhub</li><li>Databricks</li><li>Anyscale</li><li>Mosaic</li><li>Runpod</li><li>Modal</li></ol></li></ol></li></ol></li></ol></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li><a href=/ data-ctx="notes/Emerging Architectures for LLM apps" data-src=/ class=internal-link>ðŸª´ Sehra's Second Brain</a></li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://secondbrain.chiragsehra.dev/js/graph.6579af7b10c818dbd2ca038702db0224.js></script></div></div><div id=contact_buttons><footer><p></p><ul><li><a href=https://secondbrain.chiragsehra.dev/>Home</a></li><li><a href=https://twitter.com/HashChirag>Twitter</a></li><li><a href=https://github.com/chiragsehra>GitHub</a></li><li><a href=https://www.linkedin.com/in/chiragsehra>Linkedin</a></li></ul></footer></div></div></body></html>